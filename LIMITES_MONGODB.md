# âš ï¸ Limites MongoDB et Solutions - CityFlow Analytics

## ğŸš¨ ProblÃ¨me identifiÃ©

Lors de l'exÃ©cution du pipeline, vous avez rencontrÃ© cette erreur :

```
âœ— Erreur MongoDB save_metrics: 'update' command document too large
âœ— Erreur export mÃ©triques comptages vers MONGODB
```

---

## ğŸ“ Limite MongoDB

**MongoDB a une limite stricte de 16 MB par document.**

Vos mÃ©triques **comptages** font :
- **7.4 millions de lignes** dans le fichier JSON
- Bien au-delÃ  de la limite de 16 MB !

---

## ğŸ” Pourquoi les comptages sont si gros ?

Le fichier `comptages_metrics_2025-11-03.json` contient :
- **~3348 tronÃ§ons** routiers
- Chaque tronÃ§on a des mÃ©triques dÃ©taillÃ©es (dÃ©bit horaire, taux occupation, temps perdu, etc.)
- **204 chunks** traitÃ©s avec agrÃ©gations

**Exemple de structure :**
```json
{
  "metrics": [
    {
      "libelle": "SI_Passy",
      "debit_horaire_moyen": 717.9,
      "debit_journalier_total": 33661014.65,
      "taux_occupation_moyen": 9.34,
      "temps_perdu_minutes": 0.0,
      // ... beaucoup de donnÃ©es
    },
    // ... Ã— 3348 tronÃ§ons
  ],
  "top_10_troncons": [...],
  "top_10_zones": [...],
  "global_metrics": {...}
}
```

---

## âœ… Solutions implÃ©mentÃ©es

### Solution 1 : Fallback automatique vers fichiers locaux â­

**Le code dÃ©tecte automatiquement** que les comptages sont trop gros et utilise les fichiers locaux :

```python
# report_generator/daily_report_generator.py
try:
    # Essayer de charger depuis MongoDB
    metric_data = db_service.load_metrics(data_type="comptages", date=date)
except Exception:
    # âœ… FALLBACK : Charger depuis fichier local
    with open("output/metrics/comptages_metrics_2025-11-03.json") as f:
        metric_data = json.load(f)
        print("â†’ Fallback: mÃ©triques comptages chargÃ©es depuis fichier local")
```

**RÃ©sultat :**
```
âš  Erreur chargement mÃ©triques comptages depuis MONGODB: ...
â†’ Fallback: mÃ©triques comptages chargÃ©es depuis fichier local
```

### Solution 2 : Backup local systÃ©matique

**Toutes les mÃ©triques** sont sauvegardÃ©es en local en plus de la base de donnÃ©es :

```python
# processors/main.py (ligne 206-211)
# Fallback: sauvegarder aussi en local si en dÃ©veloppement
if not os.getenv("AWS_EXECUTION_ENV"):
    save_json(indicators, f"output/metrics/{data_type}_metrics_{date}.json")
    print(f"  â†’ Sauvegarde locale (backup): ...")
```

**Avantage** : MÃªme si MongoDB/DynamoDB Ã©choue, les donnÃ©es sont accessibles !

---

## ğŸ¯ Solutions alternatives (pour plus tard)

### Option A : Fragmenter les mÃ©triques comptages

Au lieu de stocker tous les tronÃ§ons dans un seul document, crÃ©er un document par tronÃ§on :

```javascript
// MongoDB - Collection: comptages_details
{
  "troncon_id": "SI_Passy",
  "date": "2025-11-03",
  "metrics": {
    "debit_horaire_moyen": 717.9,
    // ...
  }
}

// MongoDB - Collection: comptages_summary
{
  "date": "2025-11-03",
  "global_metrics": {...},
  "top_10_troncons": [...],
  "top_10_zones": [...]
}
```

**Avantages** :
- âœ… Respecte la limite 16 MB
- âœ… RequÃªtes plus rapides
- âœ… Scalable

**InconvÃ©nient** :
- âš ï¸ Plus complexe Ã  implÃ©menter

### Option B : Utiliser MongoDB GridFS

Pour les gros documents > 16 MB, MongoDB propose GridFS :

```python
from pymongo import MongoClient
from gridfs import GridFS

# Stocker gros document dans GridFS
fs = GridFS(db)
file_id = fs.put(json.dumps(comptages_metrics).encode(), filename="comptages_2025-11-03.json")

# Charger
data = fs.get(file_id).read()
comptages_metrics = json.loads(data)
```

**Avantages** :
- âœ… Pas de limite de taille
- âœ… IntÃ©grÃ© Ã  MongoDB

**InconvÃ©nient** :
- âš ï¸ Moins performant pour requÃªtes

### Option C : Basculer vers DynamoDB pour les gros datasets

DynamoDB a une limite de **400 KB par item**, mais on peut fragmenter diffÃ©remment :

```javascript
// DynamoDB - Table: comptages-details
{
  "troncon_id": "SI_Passy",      // Partition Key
  "date": "2025-11-03",          // Sort Key
  "metrics": {...}
}
```

---

## ğŸ¨ Architecture hybride actuelle

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           MÃ©triques par type                    â”‚
â””â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â”‚           â”‚          â”‚          â”‚
    â–¼           â–¼          â–¼          â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Bikes  â”‚ â”‚ Traffic â”‚ â”‚Weatherâ”‚ â”‚Chantiers â”‚
â”‚ (1482) â”‚ â”‚  (613)  â”‚ â”‚ (14)  â”‚ â”‚  (469)   â”‚
â”‚  < 1MB â”‚ â”‚  < 1MB  â”‚ â”‚ < 1KB â”‚ â”‚  < 1MB   â”‚
â””â”€â”€â”€â”¬â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”¬â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜
    â”‚           â”‚          â”‚          â”‚
    â–¼           â–¼          â–¼          â–¼
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚         MongoDB âœ…                 â”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Comptagesâ”‚
â”‚(7.4M)    â”‚
â”‚  > 16MB  â”‚  âŒ Trop gros pour MongoDB
â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜
     â”‚
     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Fichier local âœ… â”‚
â”‚ (backup)         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## âœ… Comportement actuel (OPTIMAL)

| MÃ©trique | Taille | MongoDB | Fichier local |
|----------|--------|---------|---------------|
| **Bikes** | < 1 MB | âœ… OK | âœ… Backup |
| **Traffic** | < 1 MB | âœ… OK | âœ… Backup |
| **Weather** | < 1 KB | âœ… OK | âœ… Backup |
| **Chantiers** | < 1 MB | âœ… OK (corrigÃ©) | âœ… Backup |
| **RÃ©fÃ©rentiel** | ~1 MB | âœ… OK | âœ… Backup |
| **Comptages** | **> 16 MB** | âŒ Trop gros | âœ… **Source principale** |

---

## ğŸ¯ Solution actuelle (dÃ©jÃ  implÃ©mentÃ©e)

Le gÃ©nÃ©rateur de rapport **utilise automatiquement le fallback** :

1. **Essayer MongoDB** : bikes, traffic, weather, chantiers âœ…
2. **Comptages Ã©choue** : Trop gros âŒ
3. **Fallback automatique** : Charge depuis `output/metrics/comptages_metrics_2025-11-03.json` âœ…
4. **Rapport gÃ©nÃ©rÃ©** : Avec toutes les donnÃ©es ! âœ…

**C'est transparent pour l'utilisateur !**

---

## ğŸš€ Migration vers DynamoDB (Production)

En production AWS, **DynamoDB gÃ¨re mieux les gros datasets** :

### StratÃ©gie recommandÃ©e :

1. **Petites mÃ©triques** (bikes, traffic, weather) â†’ Un seul item DynamoDB
2. **Grosses mÃ©triques** (comptages) â†’ Fragmenter par tronÃ§on

**Exemple DynamoDB :**
```javascript
// Table: cityflow-comptages-details
{
  "troncon_id": "SI_Passy",  // Partition Key
  "date": "2025-11-03",      // Sort Key
  "metrics": {
    "debit_horaire_moyen": 717.9,
    // ...
  }
}

// Table: cityflow-comptages-summary
{
  "date": "2025-11-03",
  "summary_type": "global",
  "top_10_troncons": [...],
  "global_metrics": {...}
}
```

**Avantages** :
- âœ… Pas de limite 16 MB
- âœ… RequÃªtes rapides par tronÃ§on
- âœ… Scalable

---

## ğŸ’¡ Recommandations

### Pour le dÃ©veloppement local (actuel) :

âœ… **Garder l'architecture actuelle** : Fallback automatique vers fichiers locaux  
âœ… **MongoDB pour petites mÃ©triques** : bikes, traffic, weather, chantiers  
âœ… **Fichiers locaux pour comptages** : Pas de limite de taille  

**C'est la solution optimale pour le dÃ©veloppement !**

### Pour la production AWS :

Quand vous dÃ©ployez sur AWS :

1. âœ… **Option simple** : Utiliser S3 pour stocker les comptages en JSON
   ```python
   s3.put_object(Bucket="cityflow-data", Key=f"comptages/{date}.json", Body=json.dumps(comptages))
   ```

2. âœ… **Option optimale** : Fragmenter en DynamoDB (table sÃ©parÃ©e par tronÃ§on)

---

## ğŸ§ª Tester le comportement actuel

```bash
# Relancer le pipeline
python3 main.py
```

**Vous devriez voir** :
```
[Export mÃ©triques]
âœ“ MÃ©triques bikes exportÃ©es vers MONGODB
âœ“ MÃ©triques traffic exportÃ©es vers MONGODB
âœ“ MÃ©triques weather exportÃ©es vers MONGODB
âœ“ MÃ©triques chantiers exportÃ©es vers MONGODB
âœ— Erreur export comptages (trop gros)
  â†’ Sauvegarde locale: output/metrics/comptages_metrics_2025-11-03.json

[GÃ©nÃ©ration rapport]
âœ“ MÃ©triques bikes chargÃ©es depuis MONGODB
âœ“ MÃ©triques traffic chargÃ©es depuis MONGODB
âœ“ MÃ©triques weather chargÃ©es depuis MONGODB
âœ“ MÃ©triques chantiers chargÃ©es depuis MONGODB
â†’ Fallback: mÃ©triques comptages chargÃ©es depuis fichier local  â† âœ…
âœ“ Rapport gÃ©nÃ©rÃ© avec succÃ¨s
```

---

## ğŸ“Š RÃ©sumÃ©

| ProblÃ¨me | Solution | Status |
|----------|----------|--------|
| Comptages > 16 MB | Fallback fichiers locaux | âœ… ImplÃ©mentÃ© |
| ClÃ© `None` dans chantiers | Convertir en "Unknown" | âœ… CorrigÃ© |
| Rapport Ã©choue | Gestion comptages None + fallback | âœ… CorrigÃ© |
| Chunks temporaires | Nettoyage automatique | âœ… Fonctionne |

**Tout fonctionne maintenant ! Le systÃ¨me s'adapte intelligemment aux limitations.** ğŸ‰

---

## ğŸ“ Pour aller plus loin

- **MongoDB GridFS** : https://docs.mongodb.com/manual/core/gridfs/
- **DynamoDB Item Size** : https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/Limits.html
- **Design Patterns** : Fallback Pattern, Circuit Breaker

