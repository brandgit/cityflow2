# Architecture du Code de Traitement CityFlow Analytics

## ğŸ“ Structure des RÃ©pertoires

```
cityflow/
â”œâ”€â”€ main.py                          # Point d'entrÃ©e principal
â”œâ”€â”€ config/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ settings.py                  # Configuration (chemins, paramÃ¨tres)
â”œâ”€â”€ processors/                      # Processeurs par type de donnÃ©es
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ base_processor.py            # Classe abstraite de base
â”‚   â”œâ”€â”€ bikes_processor.py           # Traitements API Bikes
â”‚   â”œâ”€â”€ traffic_processor.py         # Traitements API Traffic RATP
â”‚   â”œâ”€â”€ weather_processor.py        # Traitements API Weather
â”‚   â”œâ”€â”€ comptages_processor.py       # Traitements Batch Comptages (CRITIQUE)
â”‚   â”œâ”€â”€ chantiers_processor.py       # Traitements Batch Chantiers
â”‚   â””â”€â”€ referentiel_processor.py     # Traitements RÃ©fÃ©rentiel GÃ©ographique
â”œâ”€â”€ utils/                           # Utilitaires partagÃ©s
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ validators.py                # Fonctions de validation
â”‚   â”œâ”€â”€ aggregators.py              # Fonctions d'agrÃ©gation communes
â”‚   â”œâ”€â”€ geo_utils.py                # Utilitaires gÃ©ographiques (longueur, intersection)
â”‚   â”œâ”€â”€ time_utils.py               # Utilitaires temporels (parsing dates, jour type)
â”‚   â”œâ”€â”€ traffic_calculations.py      # Calculs spÃ©cifiques trafic (temps perdu, etc.)
â”‚   â””â”€â”€ file_utils.py                # Utilitaires fichiers (CSV, JSON)
â””â”€â”€ models/                          # ModÃ¨les de donnÃ©es
    â”œâ”€â”€ __init__.py
    â”œâ”€â”€ bike_metrics.py              # ModÃ¨les mÃ©triques bikes
    â”œâ”€â”€ traffic_metrics.py           # ModÃ¨les mÃ©triques trafic
    â”œâ”€â”€ weather_metrics.py           # ModÃ¨les mÃ©triques mÃ©tÃ©o
    â””â”€â”€ daily_report.py              # ModÃ¨le rapport quotidien
```

## ğŸ—ï¸ Architecture des Classes Processeurs

### Classe Abstraite de Base

```python
# processors/base_processor.py
class BaseProcessor:
    """
    Classe abstraite pour tous les processeurs de donnÃ©es.
    Chaque processeur implÃ©mente : validate, aggregate, calculate_indicators
    """
    def validate_and_clean(self, data):
        """Validation et nettoyage des donnÃ©es brutes"""
        raise NotImplementedError
    
    def aggregate_daily(self, cleaned_data):
        """AgrÃ©gations quotidiennes"""
        raise NotImplementedError
    
    def calculate_indicators(self, aggregated_data):
        """Calculs d'indicateurs avancÃ©s"""
        raise NotImplementedError
    
    def process(self, raw_data):
        """Pipeline complet : validate â†’ aggregate â†’ calculate"""
        cleaned = self.validate_and_clean(raw_data)
        aggregated = self.aggregate_daily(cleaned)
        indicators = self.calculate_indicators(aggregated)
        return indicators
```

### Structure d'un Processeur SpÃ©cifique

```python
# processors/bikes_processor.py
class BikesProcessor(BaseProcessor):
    def __init__(self, config):
        self.config = config
    
    def validate_and_clean(self, data):
        """Validation coordonnÃ©es GPS, dÃ©tection dÃ©faillances"""
        # Appel utils/validators.py
        pass
    
    def aggregate_daily(self, cleaned_data):
        """AgrÃ©gations : total/jour, pic horaire, par arrondissement"""
        # Appel utils/aggregators.py
        pass
    
    def calculate_indicators(self, aggregated_data):
        """Indice frÃ©quentation, dÃ©tection anomalies"""
        # Appel utils/traffic_calculations.py
        pass
```

## ğŸ”„ Flux de Traitement

```
main.py
  â”‚
  â”œâ”€â†’ Chargement configuration (config/settings.py)
  â”‚
  â”œâ”€â†’ Initialisation processeurs
  â”‚   â”œâ”€â†’ BikesProcessor
  â”‚   â”œâ”€â†’ TrafficProcessor
  â”‚   â”œâ”€â†’ WeatherProcessor
  â”‚   â”œâ”€â†’ ComptagesProcessor (âš ï¸ avec gestion chunks EC2)
  â”‚   â”œâ”€â†’ ChantiersProcessor
  â”‚   â””â”€â†’ ReferentielProcessor
  â”‚
  â”œâ”€â†’ Pour chaque type de donnÃ©es :
  â”‚   â”‚
  â”‚   â”œâ”€â†’ 1. VALIDATION & NETTOYAGE
  â”‚   â”‚   â”œâ”€â†’ processors/[type]_processor.py â†’ validate_and_clean()
  â”‚   â”‚   â”œâ”€â†’ utils/validators.py (fonctions rÃ©utilisables)
  â”‚   â”‚   â””â”€â†’ Retourne : donnÃ©es nettoyÃ©es
  â”‚   â”‚
  â”‚   â”œâ”€â†’ 2. AGRÃ‰GATIONS QUOTIDIENNES
  â”‚   â”‚   â”œâ”€â†’ processors/[type]_processor.py â†’ aggregate_daily()
  â”‚   â”‚   â”œâ”€â†’ utils/aggregators.py (fonctions communes)
  â”‚   â”‚   â””â”€â†’ Retourne : donnÃ©es agrÃ©gÃ©es
  â”‚   â”‚
  â”‚   â”œâ”€â†’ 3. CALCULS D'INDICATEURS
  â”‚   â”‚   â”œâ”€â†’ processors/[type]_processor.py â†’ calculate_indicators()
  â”‚   â”‚   â”œâ”€â†’ utils/traffic_calculations.py (calculs spÃ©cifiques)
  â”‚   â”‚   â””â”€â†’ Retourne : indicateurs finaux
  â”‚   â”‚
  â”‚   â””â”€â†’ Stockage rÃ©sultats (prÃ©paration DynamoDB/S3)
  â”‚
  â””â”€â†’ GÃ©nÃ©ration rapport quotidien
      â””â”€â†’ models/daily_report.py â†’ format JSON/CSV
```

## ğŸ“¦ Modules Utilitaires

### `utils/validators.py`
```python
def validate_coordinates(lon, lat)
def validate_date_iso(date_string)
def detect_failing_sensors(data, threshold_hours)
def validate_geojson(geo_shape)
def normalize_traffic_status(etat_trafic)
```

### `utils/aggregators.py`
```python
def aggregate_by_hour(data, date_field)
def aggregate_by_arrondissement(data, geo_field)
def calculate_daily_total(data, count_field)
def calculate_hourly_average(data)
def find_peak_hour(data, count_field)
```

### `utils/geo_utils.py`
```python
def calculate_line_length(geo_shape_linestring)  # mÃ¨tres
def calculate_polygon_area(geo_shape_polygon)    # mÂ²
def point_in_polygon(point, polygon)             # intersection
def get_arrondissement_from_coordinates(lon, lat)
```

### `utils/time_utils.py`
```python
def parse_iso_date(date_string)
def get_day_type(date)  # "Lundi", "Mardi", "Weekend", "FÃ©riÃ©"
def calculate_time_difference(date1, date2)
def normalize_hour(hour)
```

### `utils/traffic_calculations.py`
```python
def calculate_lost_time(debit, taux_occupation, longueur_metres, vitesse_ref)
def calculate_observed_speed(taux_occupation, vitesse_ref)
def detect_congestion_alerts(data, seuil_taux=80, duree_min=120)
def calculate_traffic_reliability_index(data)
def compare_to_day_type(current_data, day_type_profile)
```

### `utils/file_utils.py`
```python
def load_csv(file_path, separator=';')
def save_csv(data, file_path)
def load_json(file_path)
def save_json(data, file_path)
def chunk_file(file_path, chunk_size)
```

## ğŸ¯ ModÃ¨les de DonnÃ©es

### `models/traffic_metrics.py`
```python
@dataclass
class TrafficMetrics:
    date: str
    identifiant_arc: str
    libelle: str
    debit_horaire_moyen: float
    debit_journalier_total: float
    debit_max: float
    taux_occupation_moyen: float
    etat_trafic_dominant: str
    heure_pic: str
    temps_perdu_minutes: float
    temps_perdu_total_minutes: float
    congestion_alerte: bool
    arrondissement: str
    geo_point_2d: dict
```

### `models/daily_report.py`
```python
@dataclass
class DailyReport:
    date: str
    generated_at: str
    summary: dict
    top_10_troncons_frequentes: list
    top_10_zones_congestionnees: list
    capteurs_defaillants: list
    alertes_congestion: list
    chantiers_actifs: list
```

## âš™ï¸ Configuration

### `config/settings.py`
```python
# Chemins fichiers
BATCH_DATA_PATH = "bucket-cityflow-paris-s3-raw/cityflow-raw/raw/batch/"
API_DATA_PATH = "bucket-cityflow-paris-s3-raw/cityflow-raw/raw/api/"

# ParamÃ¨tres traitement
CHUNK_SIZE = 10000  # lignes par chunk
EC2_CHUNK_SIZE = 100000  # lignes pour traitement EC2

# Seuils
TAUX_OCCUPATION_SEUIL = 80  # % pour alerte congestion
TEMPS_PERDU_VITESSE_REF = 50  # km/h
CAPTEUR_DEFAILLANT_HEURES = 6  # heures sans donnÃ©es

# Arrondissements Paris
ARRONDISSEMENTS = list(range(75001, 75021))
```

## ğŸš€ Point d'EntrÃ©e Main

### `main.py` Structure

```python
def main():
    """Point d'entrÃ©e principal"""
    
    # 1. Chargement configuration
    config = load_config()
    
    # 2. Initialisation processeurs
    processors = initialize_processors(config)
    
    # 3. Chargement donnÃ©es brutes
    raw_data = load_raw_data(config)
    
    # 4. Traitement par type
    results = {}
    for data_type, processor in processors.items():
        results[data_type] = processor.process(raw_data[data_type])
    
    # 5. Jointures multi-sources (optionnel)
    enriched_results = enrich_multi_source(results)
    
    # 6. GÃ©nÃ©ration rapport
    daily_report = generate_daily_report(results, enriched_results)
    
    # 7. Export (simulation DynamoDB/S3)
    export_results(results, daily_report, config)
    
    return daily_report
```

## ğŸ”— DÃ©pendances entre Processeurs

```
ReferentielProcessor (1er)
  â”‚
  â””â”€â†’ Enrichit les autres processeurs
      â”‚
      â”œâ”€â†’ ComptagesProcessor (jointure Identifiant arc)
      â”‚
      â”œâ”€â†’ ChantiersProcessor (enrichissement gÃ©ographique)
      â”‚
      â””â”€â†’ BikesProcessor (enrichissement arrondissement)

ComptagesProcessor
  â”‚
  â”œâ”€â†’ Calcule temps perdu
  â”‚
  â”œâ”€â†’ DÃ©tecte alertes congestion
  â”‚
  â””â”€â†’ GÃ©nÃ¨re Top 10

ChantiersProcessor
  â”‚
  â””â”€â†’ Jointure avec ComptagesProcessor (intersection gÃ©ographique)
      â””â”€â†’ Ajuste temps perdu selon prÃ©sence chantier

WeatherProcessor
  â”‚
  â””â”€â†’ CorrÃ©lation avec BikesProcessor et ComptagesProcessor
      â””â”€â†’ Impact mÃ©tÃ©o sur mobilitÃ©
```

## ğŸ“Š Flux de DonnÃ©es DÃ©taillÃ©

### Pour Comptages Routiers (Cas Critique)

```
1. Chargement fichier CSV (6.2 GB)
   â””â”€â†’ utils/file_utils.py â†’ load_csv()

2. DÃ©tection si fichier > limite
   â””â”€â†’ Si oui : dÃ©coupe en chunks
   â””â”€â†’ utils/file_utils.py â†’ chunk_file()

3. Pour chaque chunk :
   â”œâ”€â†’ ComptagesProcessor.validate_and_clean()
   â”‚   â”œâ”€â†’ utils/validators.py â†’ validate_date_iso()
   â”‚   â”œâ”€â†’ utils/validators.py â†’ validate_geojson()
   â”‚   â””â”€â†’ utils/geo_utils.py â†’ get_arrondissement_from_coordinates()
   â”‚
   â”œâ”€â†’ ComptagesProcessor.aggregate_daily()
   â”‚   â”œâ”€â†’ utils/aggregators.py â†’ aggregate_by_hour()
   â”‚   â”œâ”€â†’ utils/aggregators.py â†’ calculate_daily_total()
   â”‚   â””â”€â†’ utils/aggregators.py â†’ calculate_hourly_average()
   â”‚
   â””â”€â†’ ComptagesProcessor.calculate_indicators()
       â”œâ”€â†’ utils/traffic_calculations.py â†’ calculate_lost_time()
       â”œâ”€â†’ utils/traffic_calculations.py â†’ detect_congestion_alerts()
       â””â”€â†’ utils/geo_utils.py â†’ calculate_line_length()
```

## ğŸ§ª Tests (Structure RecommandÃ©e)

```
tests/
â”œâ”€â”€ __init__.py
â”œâ”€â”€ test_validators.py
â”œâ”€â”€ test_aggregators.py
â”œâ”€â”€ test_geo_utils.py
â”œâ”€â”€ test_traffic_calculations.py
â”œâ”€â”€ test_bikes_processor.py
â”œâ”€â”€ test_comptages_processor.py
â””â”€â”€ test_daily_report.py
```

## ğŸ”’ Gestion des Erreurs

Chaque processeur doit gÃ©rer :
- Fichiers manquants
- Format de donnÃ©es invalide
- Valeurs nulles/incohÃ©rentes
- Erreurs de parsing (dates, GeoJSON)
- Timeout sur gros fichiers

Logging centralisÃ© via `logging` module Python.

## ğŸ“ Exemple d'Utilisation

```python
# main.py
from processors import BikesProcessor, ComptagesProcessor
from config import settings

# Initialisation
bikes_proc = BikesProcessor(settings)
comptages_proc = ComptagesProcessor(settings)

# Chargement donnÃ©es
raw_bikes = load_json("api/bikes/data.json")
raw_comptages = load_csv("batch/comptages.csv")

# Traitement
bikes_results = bikes_proc.process(raw_bikes)
comptages_results = comptages_proc.process(raw_comptages)

# Export
save_json(bikes_results, "output/bikes_metrics.json")
save_json(comptages_results, "output/traffic_metrics.json")
```

