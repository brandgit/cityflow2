# ğŸ“¥ Lecture Automatique depuis S3

## ğŸ¯ FonctionnalitÃ© AjoutÃ©e

Le code peut dÃ©sormais **lire automatiquement** les donnÃ©es brutes depuis S3 en mode AWS, tout en conservant le mode local pour le dÃ©veloppement.

## ğŸ”„ DÃ©tection Automatique

Le systÃ¨me dÃ©tecte automatiquement l'environnement et choisit la source de donnÃ©es appropriÃ©e :

```python
# DÃ©tection dans processors/main.py
def load_raw_data(config):
    # ğŸ  Mode Local â†’ Lecture depuis fichiers locaux
    if not AWS_EXECUTION_ENV and not USE_S3:
        return load_raw_data_from_local(config)
    
    # â˜ï¸ Mode AWS â†’ TÃ©lÃ©chargement depuis S3
    else:
        return load_raw_data_from_s3(config)
```

---

## âš™ï¸ Configuration

### ğŸ  Mode Local (DÃ©veloppement)

**Fichier `.env` :**

```bash
# Base de donnÃ©es
DATABASE_TYPE=mongodb
MONGODB_URL=mongodb://localhost:27017/

# Pas besoin de S3
USE_S3=false

# DonnÃ©es lues depuis fichiers locaux
# bucket-cityflow-paris-s3-raw/cityflow-raw/raw/
```

**RÃ©sultat :**
- âœ… Lecture depuis fichiers locaux
- âœ… MongoDB pour stockage mÃ©triques
- âœ… Pas de connexion AWS nÃ©cessaire

---

### â˜ï¸ Mode AWS EC2

**Fichier `.env` sur EC2 :**

```bash
# Environnement AWS
AWS_EXECUTION_ENV=AWS_EC2
AWS_REGION=eu-west-3

# Base de donnÃ©es
DATABASE_TYPE=dynamodb
USE_DYNAMODB=true

# S3 activÃ© pour lecture donnÃ©es brutes
USE_S3=true
S3_RAW_BUCKET=cityflow-raw-data
S3_RAW_PREFIX=raw

# Tables DynamoDB
DYNAMODB_METRICS_TABLE=cityflow-metrics
DYNAMODB_REPORTS_TABLE=cityflow-daily-reports

# Cache local pour fichiers S3
S3_CACHE_DIR=/home/ubuntu/cityflow/s3_cache
```

**RÃ©sultat :**
- âœ… TÃ©lÃ©chargement automatique depuis S3
- âœ… Cache local pour Ã©viter re-tÃ©lÃ©chargement
- âœ… DynamoDB pour stockage mÃ©triques
- âœ… Export rapports vers S3

---

## ğŸ“Š Structure S3 Attendue

Le code s'attend Ã  trouver les donnÃ©es dans S3 selon cette structure :

```
s3://cityflow-raw-data/
â””â”€â”€ raw/
    â”œâ”€â”€ api/
    â”‚   â”œâ”€â”€ bikes/
    â”‚   â”‚   â””â”€â”€ dt=2025-11-04/
    â”‚   â”‚       â””â”€â”€ hour=02/
    â”‚   â”‚           â””â”€â”€ bikes_data.json
    â”‚   â”œâ”€â”€ traffic/
    â”‚   â”‚   â””â”€â”€ dt=2025-11-04/
    â”‚   â”‚       â””â”€â”€ hour=02/
    â”‚   â”‚           â””â”€â”€ traffic_data.json
    â”‚   â””â”€â”€ weather/
    â”‚       â””â”€â”€ dt=2025-11-04/
    â”‚           â””â”€â”€ hour=02/
    â”‚               â””â”€â”€ weather_data.json
    â””â”€â”€ batch/
        â”œâ”€â”€ comptages-routiers-permanents-2.csv
        â”œâ”€â”€ chantiers-perturbants-la-circulation.csv
        â””â”€â”€ referentiel-geographique-pour-les-donnees-trafic-issues-des-capteurs-permanents.csv
```

---

## ğŸš€ Fonctions S3 AjoutÃ©es

### Dans `utils/aws_services.py`

**1. Lister les fichiers S3**

```python
def list_s3_files(bucket_name: str, prefix: str, extension: str = None) -> List[str]:
    """Liste tous les fichiers dans un bucket/prÃ©fixe S3"""
    pass
```

**2. TÃ©lÃ©charger un fichier S3**

```python
def download_s3_file_to_temp(bucket_name: str, s3_key: str, local_dir: str) -> str:
    """TÃ©lÃ©charge un fichier S3 vers un rÃ©pertoire local temporaire"""
    pass
```

**3. TÃ©lÃ©charger un rÃ©pertoire S3**

```python
def download_s3_directory(bucket_name: str, s3_prefix: str, local_dir: str, 
                         extensions: List[str] = None) -> List[str]:
    """TÃ©lÃ©charge tous les fichiers d'un "rÃ©pertoire" S3"""
    pass
```

**4. Charger JSON depuis S3**

```python
def load_json_from_s3(bucket_name: str, s3_key: str) -> Dict:
    """Charge un fichier JSON directement depuis S3 (sans tÃ©lÃ©chargement)"""
    pass
```

---

## ğŸ”§ Flux de Traitement

### ğŸ  Mode Local

```
1. DÃ©marrage â†’ DÃ©tection environnement (LOCAL)
2. load_raw_data() â†’ load_raw_data_from_local()
3. Lecture fichiers depuis bucket-cityflow-paris-s3-raw/
4. Traitement donnÃ©es
5. Export vers MongoDB + fichiers locaux
```

### â˜ï¸ Mode AWS EC2

```
1. DÃ©marrage â†’ DÃ©tection environnement (AWS)
2. load_raw_data() â†’ load_raw_data_from_s3()
3. TÃ©lÃ©chargement depuis S3 â†’ Cache local (s3_cache/)
4. Traitement donnÃ©es
5. Export vers DynamoDB + S3
```

---

## ğŸ“ Exemple d'Utilisation

### Test en Local (Mode Simulation)

```bash
# .env
USE_S3=true  # Force le mode S3 mÃªme en local (simulation)
S3_RAW_BUCKET=cityflow-raw-data
S3_RAW_PREFIX=raw

# Lancer le traitement
python3 main.py
```

**RÃ©sultat :**
```
â˜ï¸  Mode AWS dÃ©tectÃ© - TÃ©lÃ©chargement depuis S3...
ğŸ“¥ TÃ©lÃ©chargement bikes depuis S3://cityflow-raw-data/raw/api/bikes/dt=2025-11-04/hour=02/
[SIMULATION] S3.list_files(cityflow-raw-data/raw/api/bikes/dt=2025-11-04/hour=02/)
[SIMULATION] S3.download_file(cityflow-raw-data/...)
âœ“ 0 fichiers tÃ©lÃ©chargÃ©s depuis S3://cityflow-raw-data/raw/api/bikes/dt=2025-11-04/hour=02/
```

### Test sur EC2 (RÃ©el)

```bash
# Sur EC2 avec rÃ´le IAM configurÃ©

# .env
AWS_EXECUTION_ENV=AWS_EC2
USE_S3=true
S3_RAW_BUCKET=cityflow-raw-data

# Lancer le traitement
python3 main.py
```

**RÃ©sultat :**
```
â˜ï¸  Mode AWS dÃ©tectÃ© - TÃ©lÃ©chargement depuis S3...
ğŸ“¥ TÃ©lÃ©chargement bikes depuis S3://cityflow-raw-data/raw/api/bikes/dt=2025-11-04/hour=02/
âœ“ TÃ©lÃ©chargÃ© depuis S3: raw/api/bikes/dt=2025-11-04/hour=02/bikes_data.json â†’ s3_cache/bikes/bikes_data.json
âœ“ 3 fichiers tÃ©lÃ©chargÃ©s depuis S3://cityflow-raw-data/raw/api/bikes/dt=2025-11-04/hour=02/
ğŸ“¥ TÃ©lÃ©chargement traffic depuis S3://...
...
âœ“ TÃ©lÃ©chargement depuis S3 terminÃ©
```

---

## ğŸ¯ Avantages

### âœ… **Automatique**
- DÃ©tection environnement automatique
- Pas besoin de changer le code

### âœ… **Cache Local**
- Fichiers tÃ©lÃ©chargÃ©s une fois
- RÃ©utilisÃ©s si dÃ©jÃ  prÃ©sents
- Ã‰conomise bande passante

### âœ… **Fallback**
- Si S3 Ã©choue â†’ Tentative lecture locale
- Robuste et rÃ©silient

### âœ… **Transparent**
- Le reste du code ne change pas
- MÃªme interface pour local et S3

---

## ğŸ” Permissions IAM Requises (EC2)

Le rÃ´le IAM attachÃ© Ã  l'instance EC2 doit avoir :

```json
{
  "Version": "2012-10-17",
  "Statement": [
    {
      "Effect": "Allow",
      "Action": [
        "s3:ListBucket",
        "s3:GetObject"
      ],
      "Resource": [
        "arn:aws:s3:::cityflow-raw-data",
        "arn:aws:s3:::cityflow-raw-data/*"
      ]
    }
  ]
}
```

---

## ğŸ“¦ Upload des DonnÃ©es vers S3

Pour uploader vos donnÃ©es locales vers S3 :

### Option 1 : AWS CLI

```bash
# Uploader un fichier
aws s3 cp bucket-cityflow-paris-s3-raw/cityflow-raw/raw/batch/comptages-routiers-permanents-2.csv \
    s3://cityflow-raw-data/raw/batch/

# Uploader un rÃ©pertoire complet
aws s3 sync bucket-cityflow-paris-s3-raw/cityflow-raw/raw/ \
    s3://cityflow-raw-data/raw/ \
    --exclude "*.git/*"
```

### Option 2 : Script Python

```python
from utils.aws_services import S3Service

service = S3Service("cityflow-raw-data")

# Upload fichiers API
service.upload_file(
    "bucket-cityflow-paris-s3-raw/cityflow-raw/raw/api/bikes/dt=2025-11-04/hour=02/bikes_data.json",
    "raw/api/bikes/dt=2025-11-04/hour=02/bikes_data.json"
)

# Upload fichiers batch
service.upload_file(
    "bucket-cityflow-paris-s3-raw/cityflow-raw/raw/batch/comptages-routiers-permanents-2.csv",
    "raw/batch/comptages-routiers-permanents-2.csv"
)
```

---

## ğŸ§ª Tests

### Test 1 : VÃ©rifier DÃ©tection Environnement

```bash
# Local
python3 -c "
from processors.main import load_raw_data
from config import settings
import os

print('Environnement:', 'AWS' if os.getenv('AWS_EXECUTION_ENV') else 'Local')
print('USE_S3:', settings.USE_S3)
"
```

### Test 2 : Tester TÃ©lÃ©chargement S3 (Simulation)

```bash
# En local, mode simulation
python3 -c "
from utils.aws_services import list_s3_files

files = list_s3_files('cityflow-raw-data', 'raw/batch/', extension='.csv')
print('Fichiers trouvÃ©s:', len(files))
for f in files:
    print('  -', f)
"
```

### Test 3 : Pipeline Complet

```bash
# Lancer le pipeline complet
python3 main.py

# VÃ©rifier les logs
# Doit afficher : "â˜ï¸ Mode AWS dÃ©tectÃ©" ou "ğŸ  Mode Local dÃ©tectÃ©"
```

---

## ğŸ“š Variables d'Environnement ComplÃ¨tes

| Variable | Mode Local | Mode AWS EC2 | Description |
|----------|-----------|--------------|-------------|
| `AWS_EXECUTION_ENV` | - | `AWS_EC2` | DÃ©tection auto AWS |
| `AWS_REGION` | - | `eu-west-3` | RÃ©gion AWS |
| `DATABASE_TYPE` | `mongodb` | `dynamodb` | Type de BDD |
| `USE_S3` | `false` | `true` | Forcer lecture S3 |
| `S3_RAW_BUCKET` | - | `cityflow-raw-data` | Bucket donnÃ©es brutes |
| `S3_RAW_PREFIX` | - | `raw` | PrÃ©fixe S3 |
| `S3_CACHE_DIR` | - | `/home/ubuntu/cityflow/s3_cache` | Cache local |

---

## ğŸ‰ RÃ©sumÃ©

### Ce qui a Ã©tÃ© ajoutÃ© :

âœ… **Fonctions de lecture S3** dans `utils/aws_services.py`  
âœ… **DÃ©tection automatique environnement** dans `processors/main.py`  
âœ… **Variables S3** dans `config/settings.py`  
âœ… **Configuration** mise Ã  jour dans `env.example`  
âœ… **Cache local** pour performances  
âœ… **Fallback automatique** si S3 Ã©choue

### RÃ©sultat final :

**Le code fonctionne maintenant de maniÃ¨re totalement transparente :**

- ğŸ  **En local** : Lit depuis fichiers locaux, Ã©crit dans MongoDB
- â˜ï¸ **Sur EC2** : TÃ©lÃ©charge depuis S3, Ã©crit dans DynamoDB
- ğŸ”„ **Bascule automatique** selon l'environnement
- ğŸš€ **ZÃ©ro configuration manuelle** nÃ©cessaire

---

## ğŸ†˜ DÃ©pannage

### ProblÃ¨me : "Erreur lors du tÃ©lÃ©chargement depuis S3"

**Solution :**
1. VÃ©rifier les permissions IAM de l'instance EC2
2. VÃ©rifier que le bucket S3 existe : `aws s3 ls s3://cityflow-raw-data/`
3. VÃ©rifier la structure S3 : `aws s3 ls s3://cityflow-raw-data/raw/ --recursive`

### ProblÃ¨me : "Mode AWS dÃ©tectÃ© mais je suis en local"

**Solution :**
VÃ©rifier la variable `USE_S3` dans `.env` :
```bash
USE_S3=false  # Forcer mode local
```

### ProblÃ¨me : "Fichiers non trouvÃ©s dans S3"

**Solution :**
VÃ©rifier la structure S3 et les prÃ©fixes dans `.env` :
```bash
S3_RAW_PREFIX=raw  # Doit correspondre Ã  la structure dans S3
```

---

## ğŸ“ Pour plus d'infos

- Architecture complÃ¨te : `ARCHITECTURE_AWS.md`
- DÃ©ploiement EC2 : `DEPLOIEMENT_EC2_AWS.md`
- Comparaison Local/AWS : `COMPARAISON_LOCAL_AWS.md`

**Votre projet CityFlow Analytics est maintenant 100% cloud-ready ! â˜ï¸ğŸ‰**

