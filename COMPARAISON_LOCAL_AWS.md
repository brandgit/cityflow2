# üîÑ Comparaison D√©ploiement Local vs AWS

## üìä Tableau comparatif

| Aspect | üíª Local | ‚òÅÔ∏è AWS EC2 |
|--------|---------|-----------|
| **Base de donn√©es** | MongoDB | DynamoDB |
| **Stockage rapports** | `output/reports/` | S3 Bucket |
| **Stockage m√©triques** | Fichiers JSON locaux | DynamoDB + S3 |
| **D√©coupage fichiers** | Optionnel | Automatique (chunks) |
| **API** | Flask dev server | Flask ou Lambda |
| **Dashboard** | Streamlit local | Streamlit sur EC2 |
| **Automatisation** | Manuel | Cron / EventBridge |
| **Co√ªt** | Gratuit | ~$40-75/mois |
| **Disponibilit√©** | Pendant que PC allum√© | 24/7 |
| **Scalabilit√©** | Limit√©e par PC | √âlastique |

---

## üîß Diff√©rences de configuration

### Fichier .env

#### üíª Local
```bash
DATABASE_TYPE=mongodb
MONGODB_URL=mongodb://localhost:27017/
MONGODB_DATABASE=cityflow

# Chemins locaux relatifs
DATA_DIR_RAW=bucket-cityflow-paris-s3-raw/cityflow-raw/raw
OUTPUT_DIR=output
```

#### ‚òÅÔ∏è AWS EC2
```bash
AWS_EXECUTION_ENV=AWS_EC2
AWS_REGION=eu-west-3
DATABASE_TYPE=dynamodb
USE_DYNAMODB=true
USE_S3=true

# Tables et buckets AWS
DYNAMODB_TABLE_METRICS=cityflow-metrics
DYNAMODB_TABLE_REPORTS=cityflow-reports
S3_BUCKET_REPORTS=cityflow-reports-paris

# Chemins EC2
DATA_DIR_RAW=/home/ubuntu/cityflow/data/raw
OUTPUT_DIR=/home/ubuntu/cityflow/output
```

---

## üîÄ Comportement automatique du code

Le code **d√©tecte automatiquement** l'environnement et s'adapte :

### D√©tection de l'environnement

```python
# Dans utils/database_factory.py
import os

def get_database_service():
    # Si AWS_EXECUTION_ENV est d√©fini ‚Üí DynamoDB
    if os.getenv("AWS_EXECUTION_ENV"):
        return DynamoDBServiceAdapter()
    
    # Si USE_DYNAMODB=true ‚Üí DynamoDB
    if os.getenv("USE_DYNAMODB", "false").lower() == "true":
        return DynamoDBServiceAdapter()
    
    # Sinon ‚Üí MongoDB
    return MongoDBService()
```

### Export des rapports

```python
# Dans report_generator/daily_report_generator.py
def export_report(self, report):
    is_aws = os.getenv("AWS_EXECUTION_ENV") or os.getenv("USE_S3") == "true"
    
    if is_aws:
        # AWS : CSV ‚Üí S3, JSON ‚Üí DynamoDB
        save_csv_to_s3(csv_data, bucket, key)
        save_json_to_dynamodb(json_data, table)
    else:
        # Local : CSV ‚Üí output/reports/, JSON ‚Üí MongoDB
        save_csv_locally(csv_data, "output/reports/")
        save_json_to_mongodb(json_data)
```

### D√©coupage des fichiers

```python
# Dans processors/comptages_processor.py
def process_large_file(self, file_path):
    # AWS ou fichier > 500 MB ‚Üí chunks
    if os.getenv("AWS_EXECUTION_ENV") or file_size > MAX_FILE_SIZE_MB:
        chunks = chunk_file(file_path, EC2_CHUNK_SIZE)
        # Traiter par chunks
    else:
        # Fichier normal
        return self.process(data)
```

---

## üìà Flux de donn√©es

### üíª En local

```
Donn√©es brutes (local)
    ‚Üì
Processors (Python)
    ‚Üì
MongoDB (local) + Fichiers JSON
    ‚Üì
Dashboard Streamlit (local)
```

### ‚òÅÔ∏è Sur AWS

```
Donn√©es brutes (S3 ou local EC2)
    ‚Üì
Processors sur EC2 (Python)
    ‚Üì
DynamoDB + S3 (CSV)
    ‚Üì
API Flask sur EC2
    ‚Üì
Dashboard Streamlit sur EC2
```

---

## üöÄ Migration Local ‚Üí AWS

### √âtape 1 : Pr√©parer les donn√©es

```bash
# Local : Exporter MongoDB vers JSON
python3 -c "
from utils.mongodb_service import MongoDBService
import json

db = MongoDBService()
for metric_type in ['bikes', 'traffic', 'comptages', 'chantiers']:
    data = db.load_metrics(metric_type, '2025-11-04')
    if data:
        with open(f'{metric_type}_export.json', 'w') as f:
            json.dump(data, f)
"

# Uploader vers S3
aws s3 cp *.json s3://cityflow-migration/
```

### √âtape 2 : Sur EC2, importer vers DynamoDB

```bash
# Sur EC2
python3 -c "
from utils.dynamodb_service_adapter import DynamoDBServiceAdapter
import json

db = DynamoDBServiceAdapter()
for metric_type in ['bikes', 'traffic', 'comptages', 'chantiers']:
    with open(f'{metric_type}_export.json', 'r') as f:
        data = json.load(f)
        db.save_metrics(data, metric_type, '2025-11-04')
"
```

### √âtape 3 : Modifier .env

```bash
# Passer de MongoDB √† DynamoDB
sed -i 's/DATABASE_TYPE=mongodb/DATABASE_TYPE=dynamodb/' .env
sed -i 's/USE_DYNAMODB=false/USE_DYNAMODB=true/' .env
```

### √âtape 4 : Tester

```bash
python3 test_database_connection.py
```

---

## üí∞ Optimisation des co√ªts

### Option 1 : Instance Spot (jusqu'√† 90% moins cher)

```bash
# Lancer une instance spot
aws ec2 request-spot-instances \
    --instance-count 1 \
    --type "one-time" \
    --launch-specification file://spot-config.json
```

‚ö†Ô∏è **Attention :** L'instance peut √™tre interrompue

### Option 2 : Arr√™t automatique la nuit

```bash
# Arr√™ter l'instance √† 22h
0 22 * * * aws ec2 stop-instances --instance-ids i-xxxxx

# D√©marrer √† 6h
0 6 * * * aws ec2 start-instances --instance-ids i-xxxxx
```

**√âconomie :** ~50% si arr√™t 16h/jour

### Option 3 : Lambda au lieu d'EC2 (pour processors uniquement)

- Pas de co√ªt quand inactif
- Facturation √† la seconde
- Limite : 15 min d'ex√©cution max
- Id√©al pour : traitement quotidien rapide

---

## üéØ Recommandations par usage

### D√©veloppement / Test
- **Local** : MongoDB + fichiers JSON
- Gratuit, rapide √† it√©rer

### Production l√©g√®re (< 10 utilisateurs)
- **EC2 t3.medium** + DynamoDB + S3
- ~$40/mois
- Dashboard accessible 24/7

### Production intensive (> 10 utilisateurs)
- **EC2 t3.large/xlarge** + DynamoDB + S3 + CloudFront
- ~$100-200/mois
- Haute disponibilit√©

### Serverless (traitement uniquement)
- **Lambda** + DynamoDB + S3 + EventBridge
- ~$5-20/mois (usage mod√©r√©)
- Pas de maintenance de serveur

---

## ‚úÖ Checklist de migration

- [ ] Cr√©er instance EC2
- [ ] Cr√©er table DynamoDB
- [ ] Cr√©er bucket S3
- [ ] Configurer r√¥le IAM
- [ ] D√©ployer le code
- [ ] Configurer .env pour AWS
- [ ] Tester la connexion DynamoDB
- [ ] Ex√©cuter un traitement test
- [ ] V√©rifier DynamoDB et S3
- [ ] Configurer cron/systemd
- [ ] Lancer API et Dashboard
- [ ] Tester l'acc√®s externe
- [ ] Configurer monitoring
- [ ] Configurer backups

---

**Bon d√©ploiement !** üöÄ

